const Prompt = require('../models/Prompt');
const Conversation = require('../models/Conversation');
const axios = require('axios');
const Groq = require('groq-sdk');
const { GoogleGenAI } = require('@google/genai');

// Initialize Groq SDK lazily to avoid crash if key is missing on startup
let groq;
const getGroqClient = () => {
    if (!groq) {
        if (!process.env.GROQ_API_KEY) {
            throw new Error('GROQ_API_KEY is missing');
        }
        groq = new Groq({ apiKey: process.env.GROQ_API_KEY });
    }
    return groq;
};

// Initialize Gemini SDK lazily
let genAI;
const getGeminiClient = () => {
    if (!genAI) {
        if (!process.env.GEMINI_API_KEY) {
            throw new Error('GEMINI_API_KEY is missing');
        }
        genAI = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });
    }
    return genAI;
};

exports.createImage = async (req, res) => {
    try {
        const { prompt, negativePrompt, style, useGemini, conversationId } = req.body;
        const userId = req.user?.id; // Optional

        if (!process.env.GROQ_API_KEY || !process.env.HF_API_KEY) {
            console.warn('API Keys missing. Using Pollinations.ai as fallback.');
        }

        let aiData;
        let finalPrompt = prompt;

        // 1. Enhance prompt (Groq or Fallback)
        if (process.env.GROQ_API_KEY) {
            try {
                console.log('Enhancing prompt with Groq SDK...');
                const client = getGroqClient();
                const chatCompletion = await client.chat.completions.create({
                    messages: [
                        {
                            role: 'system',
                            content: 'Act as an expert AI Art prompt engineer. Return ONLY a JSON object with "enhancedPrompt" (max 200 chars optimized for Stable Diffusion) and "caption" (a short, creative 1-sentence caption).'
                        },
                        {
                            role: 'user',
                            content: `User Input: "${prompt}", Style: "${style}"`
                        }
                    ],
                    model: 'llama3-70b-8192',
                    response_format: { type: "json_object" }
                });
                aiData = JSON.parse(chatCompletion.choices[0].message.content);
                finalPrompt = aiData.enhancedPrompt || prompt;
            } catch (err) {
                console.error('Groq enhancement failed, using raw prompt:', err.message);
                aiData = { enhancedPrompt: prompt, caption: "Generated by AI" };
            }
        } else {
            aiData = { enhancedPrompt: prompt, caption: "Generated by AI (Free Mode)" };
        }

        // 2. Generate Image (HF, Gemini, or Pollinations)
        let imageUrl;

        if (useGemini && process.env.GEMINI_API_KEY) {
            try {
                console.log('Generating image with Gemini (New SDK)...');
                const client = getGeminiClient();
                
                const geminiResponse = await client.models.generateContent({
                    model: "gemini-2.5-flash-image",
                    contents: `${finalPrompt}, ${style}, high quality, 8k`,
                });

                const part = geminiResponse.candidates[0].content.parts.find(p => p.inlineData);
                
                if (part) {
                    imageUrl = `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
                } else {
                    throw new Error('No image data returned from Gemini');
                }
            } catch (err) {
                console.error('Gemini generation failed, falling back to Pollinations:', err.message);
                const encodedPrompt = encodeURIComponent(`${finalPrompt}, ${style}, high quality, 8k`);
                imageUrl = `https://image.pollinations.ai/prompt/${encodedPrompt}?nologo=true&private=true`;
            }
        } else if (process.env.HF_API_KEY) {
            try {
                console.log('Generating image with Hugging Face...');
                const hfResponse = await axios.post(
                    'https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0',
                    { inputs: `${finalPrompt}, ${style}, high quality, 8k` },
                    {
                        headers: {
                            'Authorization': `Bearer ${process.env.HF_API_KEY}`,
                            'Content-Type': 'application/json'
                        },
                        responseType: 'arraybuffer'
                    }
                );
                const base64Image = Buffer.from(hfResponse.data, 'binary').toString('base64');
                imageUrl = `data:image/png;base64,${base64Image}`;
            } catch (err) {
                console.error('HF generation failed, falling back to Pollinations:', err.message);
                const encodedPrompt = encodeURIComponent(`${finalPrompt}, ${style}, high quality, 8k`);
                imageUrl = `https://image.pollinations.ai/prompt/${encodedPrompt}?nologo=true&private=true`;
            }
        } else {
            console.log('Using Pollinations.ai for image generation (Free Mode)...');
            const encodedPrompt = encodeURIComponent(`${finalPrompt}, ${style}, high quality, 8k`);
            imageUrl = `https://image.pollinations.ai/prompt/${encodedPrompt}?nologo=true&private=true`;
        }

        const newPromptData = {
            prompt,
            enhancedPrompt: finalPrompt,
            aiResponse: aiData.caption,
            negativePrompt,
            style,
            imageUrl: imageUrl,
        };

        if (userId) {
            console.log('Saving to DB for user:', userId);
            newPromptData.user = userId;
            
            let convId = conversationId;
            if (!convId) {
                console.log('Creating new conversation...');
                const newConv = new Conversation({
                    title: prompt.substring(0, 30) + (prompt.length > 30 ? '...' : ''),
                    user: userId
                });
                const savedConv = await newConv.save();
                convId = savedConv._id;
                console.log('New conversation created:', convId);
            } else {
                await Conversation.findByIdAndUpdate(convId, { updatedAt: Date.now() });
            }
            
            newPromptData.conversation = convId;
            const newPrompt = new Prompt(newPromptData);
            await newPrompt.save();
            console.log('Prompt saved successfully');
            res.status(201).json({ success: true, data: newPrompt, conversationId: convId });
        } else {
            console.log('No userId found, not saving to DB');
            res.status(201).json({ success: true, data: newPromptData });
        }
    } catch (error) {
        console.error('Error creating image:', error.message);
        res.status(500).json({ success: false, error: 'Server Error', details: error.message });
    }
};

exports.getPrompts = async (req, res) => {
    try {
        const prompts = await Prompt.find().sort({ createdAt: -1 });
        res.status(200).json({ success: true, data: prompts });
    } catch (error) {
        console.error('Error fetching prompts:', error);
        res.status(500).json({ success: false, error: 'Server Error' });
    }
};

exports.generateText = async (req, res) => {
    try {
        const { prompt, style, conversationId } = req.body;
        if (!prompt) {
            return res.status(400).json({ success: false, message: 'Prompt is required' });
        }

        let text;
        if (process.env.GROQ_API_KEY) {
            try {
                console.log('Generating text with Groq SDK...');
                const client = getGroqClient();
                const chatCompletion = await client.chat.completions.create({
                    messages: [
                        {
                            role: 'system',
                            content: `Act as a creative assistant. Style: "${style || 'Realistic'}". Write a concise, vivid 2-3 sentence response describing the scene.`
                        },
                        {
                            role: 'user',
                            content: prompt
                        }
                    ],
                    model: 'llama3-70b-8192',
                });
                text = chatCompletion.choices[0].message.content;
            } catch (err) {
                console.error('Groq text generation failed, falling back to Pollinations:', err.message);
                const pollResponse = await axios.get(`https://text.pollinations.ai/${encodeURIComponent(prompt)}?model=openai`);
                text = pollResponse.data;
            }
        } else {
            console.log('Using Pollinations.ai for text generation (Free Mode)...');
            const pollResponse = await axios.get(`https://text.pollinations.ai/${encodeURIComponent(prompt)}?model=openai`);
            text = pollResponse.data;
        }

        const newPromptData = {
            prompt,
            aiResponse: text.trim(),
            style: style || 'Realistic',
        };

        const userId = req.user?.id;
        if (userId) {
            console.log('Saving text to DB for user:', userId);
            newPromptData.user = userId;
            
            let convId = conversationId;
            if (!convId) {
                console.log('Creating new conversation for text...');
                const newConv = new Conversation({
                    title: prompt.substring(0, 30) + (prompt.length > 30 ? '...' : ''),
                    user: userId
                });
                const savedConv = await newConv.save();
                convId = savedConv._id;
                console.log('New conversation created:', convId);
            } else {
                await Conversation.findByIdAndUpdate(convId, { updatedAt: Date.now() });
            }

            newPromptData.conversation = convId;
            const newPrompt = new Prompt(newPromptData);
            await newPrompt.save();
            console.log('Text prompt saved successfully');
            res.status(200).json({ success: true, data: newPrompt, conversationId: convId });
        } else {
            console.log('No user found for text, not saving to DB');
            res.status(200).json({ success: true, data: { prompt, aiResponse: text.trim() } });
        }
    } catch (error) {
        console.error('Error generating text:', error.message);
        res.status(500).json({ success: false, error: 'Server Error', details: error.message });
    }
};

exports.getUserPrompts = async (req, res) => {
    try {
        const prompts = await Prompt.find({ user: req.user.id }).sort({ createdAt: -1 });
        res.status(200).json({ success: true, data: prompts });
    } catch (error) {
        console.error('Error fetching user prompts:', error);
        res.status(500).json({ success: false, error: 'Server Error' });
    }
};

exports.getConversations = async (req, res) => {
    try {
        const conversations = await Conversation.find({ user: req.user.id }).sort({ updatedAt: -1 });
        res.status(200).json({ success: true, data: conversations });
    } catch (error) {
        console.error('Error fetching conversations:', error);
        res.status(500).json({ success: false, error: 'Server Error' });
    }
};

exports.getConversationPrompts = async (req, res) => {
    try {
        const prompts = await Prompt.find({ conversation: req.params.id }).sort({ createdAt: 1 });
        res.status(200).json({ success: true, data: prompts });
    } catch (error) {
        console.error('Error fetching conversation prompts:', error);
        res.status(500).json({ success: false, error: 'Server Error' });
    }
};
